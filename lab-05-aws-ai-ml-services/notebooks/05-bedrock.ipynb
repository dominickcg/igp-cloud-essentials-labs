{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ M√≥dulo 5: IA Generativa con Amazon Bedrock\n",
    "\n",
    "**Duraci√≥n**: 15 minutos  \n",
    "**Objetivo**: Aprender a generar contenido cient√≠fico usando IA generativa\n",
    "\n",
    "## üéØ ¬øQu√© aprender√°s?\n",
    "- Generar reportes cient√≠ficos autom√°ticamente\n",
    "- Crear res√∫menes de investigaci√≥n\n",
    "- Usar diferentes modelos de IA generativa\n",
    "- Aplicar prompting efectivo para casos cient√≠ficos\n",
    "- Configurar par√°metros avanzados (temperatura, top-p)\n",
    "\n",
    "## üîß Configuraci√≥n Inicial\n",
    "Ejecuta las siguientes celdas paso a paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "import sys\n",
    "!{sys.executable} -m pip install boto3 ipywidgets --quiet\n",
    "\n",
    "print(\"‚úÖ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as\n",
    "import boto3\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Configurar Credenciales AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Bedrock\n",
    "try:\n",
    "    bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "    print(\"‚úÖ Cliente Bedrock configurado\")\n",
    "    print(\"‚ö†Ô∏è Nota: Bedrock requiere acceso especial en algunas cuentas\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Configurar credenciales en la siguiente celda\")\n",
    "    bedrock_runtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n manual de credenciales\n",
    "AWS_ACCESS_KEY_ID = \"TU_ACCESS_KEY_AQUI\"\n",
    "AWS_SECRET_ACCESS_KEY = \"TU_SECRET_KEY_AQUI\"\n",
    "\n",
    "if AWS_ACCESS_KEY_ID != \"TU_ACCESS_KEY_AQUI\":\n",
    "    bedrock_runtime = boto3.client(\n",
    "        'bedrock-runtime',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    print(\"‚úÖ Credenciales configuradas manualmente\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Usar credenciales por defecto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Prompts Cient√≠ficos Predefinidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts para generaci√≥n cient√≠fica\n",
    "SCIENTIFIC_PROMPTS = {\n",
    "    \"Reporte S√≠smico\": {\n",
    "        \"prompt\": \"\"\"Genera un reporte cient√≠fico sobre actividad s√≠smica basado en estos datos:\n",
    "        \n",
    "Datos del evento:\n",
    "- Magnitud: 6.2 Mw\n",
    "- Profundidad: 45 km\n",
    "- Ubicaci√≥n: 150 km al sureste de Lima, Per√∫\n",
    "- Fecha: 15 de noviembre de 2024\n",
    "- Hora: 14:32 UTC\n",
    "\n",
    "El reporte debe incluir:\n",
    "1. Resumen ejecutivo\n",
    "2. Caracter√≠sticas del evento\n",
    "3. Impacto potencial\n",
    "4. Recomendaciones\n",
    "\n",
    "Usa terminolog√≠a t√©cnica apropiada pero mantenlo comprensible.\"\"\",\n",
    "        \"model\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    },\n",
    "    \n",
    "    \"An√°lisis Volc√°nico\": {\n",
    "        \"prompt\": \"\"\"Crea un an√°lisis cient√≠fico sobre el monitoreo volc√°nico en los Andes peruanos.\n",
    "        \n",
    "Informaci√≥n base:\n",
    "- Volcanes principales: Sabancaya, Ubinas, Misti\n",
    "- Actividad reciente: Incremento en emisiones de gases\n",
    "- Tecnolog√≠as: C√°maras t√©rmicas, sism√≥grafos, an√°lisis geoqu√≠mico\n",
    "- Poblaci√≥n en riesgo: Aproximadamente 500,000 personas\n",
    "\n",
    "El an√°lisis debe cubrir:\n",
    "1. Estado actual de los volcanes\n",
    "2. M√©todos de monitoreo utilizados\n",
    "3. Evaluaci√≥n de riesgos\n",
    "4. Estrategias de mitigaci√≥n\n",
    "\n",
    "Enf√≥cate en aspectos t√©cnicos y de gesti√≥n de riesgos.\"\"\",\n",
    "        \"model\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ü§ñ Prompts cient√≠ficos cargados:\")\n",
    "for i, (title, data) in enumerate(SCIENTIFIC_PROMPTS.items(), 1):\n",
    "    word_count = len(data['prompt'].split())\n",
    "    print(f\"  {i}. {title} ({word_count} palabras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Funci√≥n de Generaci√≥n con Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_bedrock(prompt, model_id, prompt_name, temperature=0.7, max_tokens=1000):\n",
    "    \"\"\"Genera contenido usando Amazon Bedrock con par√°metros configurables\"\"\"\n",
    "    try:\n",
    "        print(f\"üîÑ Generando: {prompt_name}\")\n",
    "        print(f\"  ü§ñ Modelo: {model_id.split('.')[-1]}\")\n",
    "        print(f\"  ‚öôÔ∏è Temperatura: {temperature}, Max tokens: {max_tokens}\")\n",
    "        \n",
    "        # Preparar el cuerpo de la solicitud para Claude\n",
    "        body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Llamar a Bedrock\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(body)\n",
    "        )\n",
    "        \n",
    "        # Procesar respuesta\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        generated_text = response_body['content'][0]['text']\n",
    "        \n",
    "        print(f\"‚úÖ Contenido generado: {len(generated_text)} caracteres\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'generated_text': generated_text,\n",
    "            'prompt_name': prompt_name,\n",
    "            'model_id': model_id,\n",
    "            'prompt': prompt\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        \n",
    "        # Simulaci√≥n si Bedrock no est√° disponible\n",
    "        print(\"üîÑ Usando simulaci√≥n de IA generativa...\")\n",
    "        \n",
    "        simulated_responses = {\n",
    "            \"Reporte S√≠smico\": \"\"\"# REPORTE S√çSMICO - EVENTO DEL 15 DE NOVIEMBRE 2024\n",
    "\n",
    "## Resumen Ejecutivo\n",
    "Se registr√≥ un evento s√≠smico de magnitud 6.2 Mw a las 14:32 UTC del 15 de noviembre de 2024, con epicentro localizado a 150 km al sureste de Lima, Per√∫, a una profundidad de 45 km.\n",
    "\n",
    "## Caracter√≠sticas del Evento\n",
    "- **Magnitud**: 6.2 Mw (moderado a fuerte)\n",
    "- **Profundidad**: 45 km (intermedio)\n",
    "- **Mecanismo**: Probable falla inversa asociada a la subducci√≥n\n",
    "- **Intensidad m√°xima estimada**: VI-VII (Escala de Mercalli)\n",
    "\n",
    "## Impacto Potencial\n",
    "El evento pudo generar sacudidas moderadas a fuertes en un radio de 100 km. Las estructuras vulnerables en la regi√≥n podr√≠an haber experimentado da√±os menores.\n",
    "\n",
    "## Recomendaciones\n",
    "1. Mantener vigilancia por posibles r√©plicas\n",
    "2. Inspeccionar infraestructura cr√≠tica\n",
    "3. Activar protocolos de respuesta establecidos\"\"\",\n",
    "            \n",
    "            \"An√°lisis Volc√°nico\": \"\"\"# AN√ÅLISIS DE MONITOREO VOLC√ÅNICO - ANDES PERUANOS\n",
    "\n",
    "## Estado Actual de los Volcanes\n",
    "Los volcanes Sabancaya, Ubinas y Misti mantienen diferentes niveles de actividad. El Sabancaya presenta actividad eruptiva continua con emisiones de ceniza, mientras que Ubinas y Misti se encuentran en estado de vigilancia.\n",
    "\n",
    "## M√©todos de Monitoreo\n",
    "- **Sismol√≥gico**: Red de 15 estaciones s√≠smicas de banda ancha\n",
    "- **Geoqu√≠mico**: An√°lisis de gases volc√°nicos (SO2, CO2, H2S)\n",
    "- **T√©rmico**: C√°maras infrarrojas para detecci√≥n de anomal√≠as\n",
    "- **Geod√©sico**: Medici√≥n de deformaci√≥n del terreno\n",
    "\n",
    "## Evaluaci√≥n de Riesgos\n",
    "Aproximadamente 500,000 personas viven en zonas de influencia volc√°nica. Los principales peligros incluyen ca√≠da de ceniza, flujos pirocl√°sticos y lahares.\n",
    "\n",
    "## Estrategias de Mitigaci√≥n\n",
    "1. Fortalecimiento del sistema de alerta temprana\n",
    "2. Capacitaci√≥n comunitaria en gesti√≥n de riesgos\n",
    "3. Desarrollo de planes de evacuaci√≥n actualizados\"\"\"\n",
    "        }\n",
    "        \n",
    "        simulated_text = simulated_responses.get(prompt_name, f\"Contenido generado para: {prompt_name}\\nPar√°metros: temperatura={temperature}, tokens={max_tokens}\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'generated_text': simulated_text,\n",
    "            'prompt_name': prompt_name,\n",
    "            'model_id': 'simulado',\n",
    "            'prompt': prompt,\n",
    "            'simulated': True\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de generaci√≥n creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Ejercicio 1: Generar Reporte S√≠smico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte s√≠smico\n",
    "prompt_name = \"Reporte S√≠smico\"\n",
    "prompt_data = SCIENTIFIC_PROMPTS[prompt_name]\n",
    "\n",
    "print(f\"üìÑ Generando: {prompt_name}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "seismic_report = generate_with_bedrock(\n",
    "    prompt=prompt_data['prompt'],\n",
    "    model_id=prompt_data['model'],\n",
    "    prompt_name=prompt_name,\n",
    "    temperature=0.5,\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "if seismic_report.get('success'):\n",
    "    print(f\"\\nü§ñ CONTENIDO GENERADO: {seismic_report['prompt_name'].upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "    display(Markdown(seismic_report['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåã Ejercicio 2: An√°lisis Volc√°nico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar an√°lisis volc√°nico\n",
    "prompt_name = \"An√°lisis Volc√°nico\"\n",
    "prompt_data = SCIENTIFIC_PROMPTS[prompt_name]\n",
    "\n",
    "print(f\"üåã Generando: {prompt_name}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "volcanic_analysis = generate_with_bedrock(\n",
    "    prompt=prompt_data['prompt'],\n",
    "    model_id=prompt_data['model'],\n",
    "    prompt_name=prompt_name,\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "if volcanic_analysis.get('success'):\n",
    "    print(f\"\\nü§ñ CONTENIDO GENERADO: {volcanic_analysis['prompt_name'].upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "    display(Markdown(volcanic_analysis['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Widget Interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget para generaci√≥n interactiva\n",
    "def interactive_generation(prompt_selection, temperature, max_tokens):\n",
    "    prompt_data = SCIENTIFIC_PROMPTS[prompt_selection]\n",
    "    \n",
    "    print(f\"ü§ñ Generando: {prompt_selection}\")\n",
    "    print(f\"‚öôÔ∏è Temperatura: {temperature}, Max tokens: {max_tokens}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result = generate_with_bedrock(\n",
    "        prompt=prompt_data['prompt'],\n",
    "        model_id=prompt_data['model'],\n",
    "        prompt_name=prompt_selection,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    if result.get('success'):\n",
    "        print(f\"\\nü§ñ CONTENIDO GENERADO: {result['prompt_name'].upper()}\")\n",
    "        print(\"=\" * 60)\n",
    "        display(Markdown(result['generated_text']))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Crear widgets\n",
    "prompt_selector = widgets.Dropdown(\n",
    "    options=list(SCIENTIFIC_PROMPTS.keys()),\n",
    "    description='Prompt:'\n",
    ")\n",
    "\n",
    "temperature_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Temperatura:'\n",
    ")\n",
    "\n",
    "tokens_slider = widgets.IntSlider(\n",
    "    value=1000,\n",
    "    min=100,\n",
    "    max=3000,\n",
    "    step=100,\n",
    "    description='Max tokens:'\n",
    ")\n",
    "\n",
    "interactive_widget = widgets.interactive(\n",
    "    interactive_generation,\n",
    "    prompt_selection=prompt_selector,\n",
    "    temperature=temperature_slider,\n",
    "    max_tokens=tokens_slider\n",
    ")\n",
    "\n",
    "display(interactive_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Casos de Uso Reales\n",
    "\n",
    "### Amazon Bedrock en Ciencias:\n",
    "- üìÑ **Generaci√≥n de reportes**: Crear documentos t√©cnicos autom√°ticamente\n",
    "- üìö **Res√∫menes de investigaci√≥n**: Sintetizar literatura cient√≠fica\n",
    "- üí° **Propuestas de proyectos**: Desarrollar ideas de investigaci√≥n\n",
    "- üîç **An√°lisis de datos**: Interpretar resultados experimentales\n",
    "- üìù **Documentaci√≥n t√©cnica**: Crear manuales y procedimientos\n",
    "- üåç **Comunicaci√≥n cient√≠fica**: Adaptar contenido para diferentes audiencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Validaci√≥n del M√≥dulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_module():\n",
    "    checks = {\n",
    "        \"Cliente configurado\": bedrock_runtime is not None,\n",
    "        \"Contenido generado\": False,\n",
    "        \"Widget usado\": False\n",
    "    }\n",
    "    \n",
    "    if 'seismic_report' in globals() and seismic_report.get('success'):\n",
    "        checks[\"Contenido generado\"] = True\n",
    "    \n",
    "    if 'volcanic_analysis' in globals() and volcanic_analysis.get('success'):\n",
    "        checks[\"Widget usado\"] = True\n",
    "    \n",
    "    print(\"üìã VALIDACI√ìN M√ìDULO 5 - BEDROCK\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for check, status in checks.items():\n",
    "        icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"{icon} {check}\")\n",
    "    \n",
    "    completed = sum(checks.values())\n",
    "    total = len(checks)\n",
    "    print(f\"\\nüìä Progreso: {completed}/{total} ({completed/total*100:.0f}%)\")\n",
    "    \n",
    "    if completed >= 2:\n",
    "        print(\"\\nüéâ ¬°M√ìDULO COMPLETADO!\")\n",
    "        print(\"‚û°Ô∏è Contin√∫a con M√≥dulo 6: Q Developer\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Completa los ejercicios faltantes\")\n",
    "    \n",
    "    return completed >= 2\n",
    "\n",
    "module_completed = validate_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Pr√≥ximo M√≥dulo\n",
    "\n",
    "**üíª M√≥dulo 6: Asistencia de C√≥digo con Amazon Q Developer**\n",
    "\n",
    "---\n",
    "\n",
    "*M√≥dulo 5 de 6 completado* ‚úÖ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}