{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📄 Módulo 2: Análisis de Texto con Amazon Comprehend\n",
    "\n",
    "**Duración**: 15 minutos  \n",
    "**Objetivo**: Aprender a extraer información de textos científicos usando IA\n",
    "\n",
    "## 🎯 ¿Qué aprenderás?\n",
    "- Analizar texto científico para extraer entidades y conceptos clave\n",
    "- Detectar sentimientos en reportes y alertas\n",
    "- Identificar frases importantes automáticamente\n",
    "- Aplicar IA a documentación técnica real\n",
    "\n",
    "## 🔧 Configuración Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "import sys\n",
    "!{sys.executable} -m pip install boto3 matplotlib pandas seaborn --quiet\n",
    "\n",
    "print(\"✅ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔑 Configurar Credenciales AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar cliente Comprehend\n",
    "try:\n",
    "    comprehend = boto3.client('comprehend', region_name='us-east-1')\n",
    "    # Probar conexión\n",
    "    comprehend.detect_dominant_language(Text=\"Test connection\")\n",
    "    print(\"✅ Credenciales AWS configuradas correctamente\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error con credenciales. Configurar manualmente en la siguiente celda\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración manual (si es necesario)\n",
    "AWS_ACCESS_KEY_ID = \"TU_ACCESS_KEY_AQUI\"\n",
    "AWS_SECRET_ACCESS_KEY = \"TU_SECRET_KEY_AQUI\"\n",
    "\n",
    "if AWS_ACCESS_KEY_ID != \"TU_ACCESS_KEY_AQUI\":\n",
    "    comprehend = boto3.client(\n",
    "        'comprehend',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    print(\"✅ Credenciales configuradas manualmente\")\n",
    "else:\n",
    "    print(\"⚠️ Reemplaza las credenciales si es necesario\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Datos Científicos de Muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos científicos\n",
    "SCIENTIFIC_TEXTS = {\n",
    "    \"Reporte Sísmico\": \"\"\"\n",
    "    El Instituto Geofísico del Perú reporta actividad sísmica significativa en la región sur. \n",
    "    Los análisis preliminares indican un evento de magnitud 6.2 Mw con epicentro a 45 kilómetros \n",
    "    de profundidad. Las estaciones de monitoreo registraron ondas P y S características de \n",
    "    sismos tectónicos. Se recomienda mantener protocolos de seguridad en las zonas urbanas cercanas.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Alerta de Emergencia\": \"\"\"\n",
    "    ALERTA SÍSMICA: Se ha detectado un sismo de magnitud 5.8 en la costa peruana. \n",
    "    Tiempo estimado de llegada a Lima: 2 minutos. Busque refugio inmediatamente. \n",
    "    Aléjese de ventanas y objetos que puedan caer. Mantenga la calma y siga los procedimientos.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Abstract Científico\": \"\"\"\n",
    "    This study analyzes volcanic activity patterns in the Andes mountain range using \n",
    "    satellite imagery and seismic data. Results show increased thermal anomalies \n",
    "    correlating with micro-seismic events. The findings suggest enhanced monitoring \n",
    "    protocols for early volcanic eruption detection.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"📚 Textos científicos cargados:\")\n",
    "for i, (title, text) in enumerate(SCIENTIFIC_TEXTS.items(), 1):\n",
    "    word_count = len(text.split())\n",
    "    print(f\"  {i}. {title} ({word_count} palabras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Función de Análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_with_comprehend(text, text_name):\n",
    "    \"\"\"Analiza texto usando Amazon Comprehend\"\"\"\n",
    "    try:\n",
    "        print(f\"🔄 Analizando: {text_name}\")\n",
    "        \n",
    "        # Limpiar texto\n",
    "        clean_text = text.strip().replace('\\n', ' ')\n",
    "        \n",
    "        # Detectar idioma\n",
    "        language_result = comprehend.detect_dominant_language(Text=clean_text)\n",
    "        dominant_language = language_result['Languages'][0]['LanguageCode']\n",
    "        print(f\"  📝 Idioma: {dominant_language}\")\n",
    "        \n",
    "        results = {\n",
    "            'text_name': text_name,\n",
    "            'language': dominant_language,\n",
    "            'word_count': len(clean_text.split())\n",
    "        }\n",
    "        \n",
    "        # Detectar entidades\n",
    "        entities_result = comprehend.detect_entities(\n",
    "            Text=clean_text,\n",
    "            LanguageCode=dominant_language\n",
    "        )\n",
    "        results['entities'] = entities_result['Entities']\n",
    "        print(f\"  🏷️ Entidades: {len(results['entities'])}\")\n",
    "        \n",
    "        # Frases clave\n",
    "        keyphrases_result = comprehend.detect_key_phrases(\n",
    "            Text=clean_text,\n",
    "            LanguageCode=dominant_language\n",
    "        )\n",
    "        results['key_phrases'] = keyphrases_result['KeyPhrases']\n",
    "        print(f\"  🔑 Frases clave: {len(results['key_phrases'])}\")\n",
    "        \n",
    "        # Sentimientos\n",
    "        sentiment_result = comprehend.detect_sentiment(\n",
    "            Text=clean_text,\n",
    "            LanguageCode=dominant_language\n",
    "        )\n",
    "        results['sentiment'] = sentiment_result['Sentiment']\n",
    "        results['sentiment_scores'] = sentiment_result['SentimentScore']\n",
    "        print(f\"  😊 Sentimiento: {results['sentiment']}\")\n",
    "        \n",
    "        results['success'] = True\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return {'success': False, 'error': str(e)}\n",
    "\n",
    "print(\"✅ Función de análisis creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Función de Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(analysis_result):\n",
    "    \"\"\"Visualiza resultados del análisis\"\"\"\n",
    "    if not analysis_result.get('success'):\n",
    "        print(f\"❌ Error: {analysis_result.get('error')}\")\n",
    "        return\n",
    "    \n",
    "    text_name = analysis_result['text_name']\n",
    "    \n",
    "    # Crear gráficos\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Análisis: {text_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Tipos de entidades\n",
    "    if analysis_result['entities']:\n",
    "        entity_types = [e['Type'] for e in analysis_result['entities']]\n",
    "        entity_counts = Counter(entity_types)\n",
    "        \n",
    "        ax1.bar(entity_counts.keys(), entity_counts.values(), color='lightblue')\n",
    "        ax1.set_title('Entidades Detectadas')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'Sin entidades', ha='center', transform=ax1.transAxes)\n",
    "        ax1.set_title('Entidades Detectadas')\n",
    "    \n",
    "    # 2. Frases clave\n",
    "    if analysis_result['key_phrases']:\n",
    "        top_phrases = sorted(analysis_result['key_phrases'], \n",
    "                           key=lambda x: x['Score'], reverse=True)[:6]\n",
    "        phrases = [p['Text'][:25] + '...' if len(p['Text']) > 25 else p['Text'] for p in top_phrases]\n",
    "        scores = [p['Score'] for p in top_phrases]\n",
    "        \n",
    "        ax2.barh(phrases, scores, color='lightgreen')\n",
    "        ax2.set_title('Frases Clave (Top 6)')\n",
    "        ax2.set_xlabel('Relevancia')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Sin frases clave', ha='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Frases Clave')\n",
    "    \n",
    "    # 3. Sentimientos\n",
    "    sentiment_scores = analysis_result['sentiment_scores']\n",
    "    sentiments = ['Positive', 'Negative', 'Neutral', 'Mixed']\n",
    "    scores = [sentiment_scores[s] for s in sentiments]\n",
    "    colors = ['green', 'red', 'gray', 'orange']\n",
    "    \n",
    "    ax3.pie(scores, labels=sentiments, colors=colors, autopct='%1.1f%%')\n",
    "    ax3.set_title(f'Sentimientos\\n(Dominante: {analysis_result[\"sentiment\"]})')\n",
    "    \n",
    "    # 4. Estadísticas\n",
    "    ax4.axis('off')\n",
    "    stats = f\"\"\"📊 Estadísticas:\n",
    "\n",
    "Palabras: {analysis_result['word_count']}\n",
    "Entidades: {len(analysis_result['entities'])}\n",
    "Frases clave: {len(analysis_result['key_phrases'])}\n",
    "Idioma: {analysis_result['language'].upper()}\"\"\"\n",
    "    ax4.text(0.1, 0.7, stats, fontsize=12, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar entidades\n",
    "    if analysis_result['entities']:\n",
    "        print(f\"\\n🏷️ ENTIDADES EN '{text_name.upper()}'\")\n",
    "        print(\"=\" * 50)\n",
    "        for entity in analysis_result['entities'][:8]:\n",
    "            print(f\"• {entity['Text']} ({entity['Type']}) - {entity['Score']:.2f}\")\n",
    "\n",
    "print(\"✅ Función de visualización creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Ejercicio 1: Análisis de Reporte Sísmico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar reporte sísmico\n",
    "text_name = \"Reporte Sísmico\"\n",
    "text_content = SCIENTIFIC_TEXTS[text_name]\n",
    "\n",
    "print(f\"📄 Analizando: {text_name}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Realizar análisis\n",
    "seismic_analysis = analyze_text_with_comprehend(text_content, text_name)\n",
    "\n",
    "# Visualizar\n",
    "if seismic_analysis.get('success'):\n",
    "    visualize_results(seismic_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚨 Ejercicio 2: Análisis de Alerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar alerta\n",
    "text_name = \"Alerta de Emergencia\"\n",
    "text_content = SCIENTIFIC_TEXTS[text_name]\n",
    "\n",
    "print(f\"🚨 Analizando: {text_name}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "alert_analysis = analyze_text_with_comprehend(text_content, text_name)\n",
    "\n",
    "if alert_analysis.get('success'):\n",
    "    visualize_results(alert_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎛️ Widget Interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget para análisis interactivo\n",
    "def interactive_analysis(text_selection):\n",
    "    text_content = SCIENTIFIC_TEXTS[text_selection]\n",
    "    print(f\"🔍 Analizando: {text_selection}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result = analyze_text_with_comprehend(text_content, text_selection)\n",
    "    if result.get('success'):\n",
    "        visualize_results(result)\n",
    "    return result\n",
    "\n",
    "# Crear widget\n",
    "text_selector = widgets.Dropdown(\n",
    "    options=list(SCIENTIFIC_TEXTS.keys()),\n",
    "    description='Texto:'\n",
    ")\n",
    "\n",
    "interactive_widget = widgets.interactive(interactive_analysis, text_selection=text_selector)\n",
    "display(interactive_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Casos de Uso Reales\n",
    "\n",
    "### Amazon Comprehend en Ciencias:\n",
    "- 📊 **Análisis de literatura**: Procesar miles de papers automáticamente\n",
    "- 🚨 **Sistemas de alerta**: Analizar tono y urgencia de comunicaciones\n",
    "- 🔍 **Extracción de datos**: Identificar entidades científicas en textos\n",
    "- 📈 **Análisis de tendencias**: Detectar patrones en grandes volúmenes de texto\n",
    "- 📝 **Clasificación**: Organizar documentos por tema y sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Validación del Módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_module():\n",
    "    checks = {\n",
    "        \"Credenciales configuradas\": False,\n",
    "        \"Análisis realizado\": False,\n",
    "        \"Widget usado\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        comprehend.detect_dominant_language(Text=\"Test\")\n",
    "        checks[\"Credenciales configuradas\"] = True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if 'seismic_analysis' in globals() and seismic_analysis.get('success'):\n",
    "        checks[\"Análisis realizado\"] = True\n",
    "        checks[\"Widget usado\"] = True\n",
    "    \n",
    "    print(\"📋 VALIDACIÓN MÓDULO 2 - COMPREHEND\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for check, status in checks.items():\n",
    "        icon = \"✅\" if status else \"❌\"\n",
    "        print(f\"{icon} {check}\")\n",
    "    \n",
    "    completed = sum(checks.values())\n",
    "    total = len(checks)\n",
    "    print(f\"\\n📊 Progreso: {completed}/{total} ({completed/total*100:.0f}%)\")\n",
    "    \n",
    "    if completed >= 2:\n",
    "        print(\"\\n🎉 ¡MÓDULO COMPLETADO!\")\n",
    "        print(\"➡️ Continúa con Módulo 3: Textract\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Completa los ejercicios faltantes\")\n",
    "    \n",
    "    return completed >= 2\n",
    "\n",
    "module_completed = validate_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🚀 Próximo Módulo\n",
    "\n",
    "**📄 Módulo 3: OCR con Amazon Textract**\n",
    "\n",
    "---\n",
    "\n",
    "*Módulo 2 de 6 completado* ✅"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}