{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“„ MÃ³dulo 2: AnÃ¡lisis de Texto con Amazon Comprehend\n",
    "\n",
    "**DuraciÃ³n**: 15 minutos  \n",
    "**Objetivo**: Aprender a extraer informaciÃ³n de textos cientÃ­ficos usando IA\n",
    "\n",
    "## ðŸŽ¯ Â¿QuÃ© aprenderÃ¡s?\n",
    "- Analizar texto cientÃ­fico para extraer entidades y conceptos clave\n",
    "- Detectar sentimientos en reportes y alertas\n",
    "- Identificar frases importantes automÃ¡ticamente\n",
    "- Aplicar IA a documentaciÃ³n tÃ©cnica real\n",
    "\n",
    "## ðŸ”§ ConfiguraciÃ³n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "import sys\n",
    "!{sys.executable} -m pip install boto3 matplotlib pandas seaborn --quiet\n",
    "\n",
    "print(\"âœ… Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerÃ­as\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Configurar Credenciales AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar cliente Comprehend\n",
    "try:\n",
    "    comprehend = boto3.client('comprehend', region_name='us-east-1')\n",
    "    # Probar conexiÃ³n\n",
    "    comprehend.detect_dominant_language(Text=\"Test connection\")\n",
    "    print(\"âœ… Credenciales AWS configuradas correctamente\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ Error con credenciales. Configurar manualmente en la siguiente celda\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n manual (si es necesario)\n",
    "AWS_ACCESS_KEY_ID = \"TU_ACCESS_KEY_AQUI\"\n",
    "AWS_SECRET_ACCESS_KEY = \"TU_SECRET_KEY_AQUI\"\n",
    "\n",
    "if AWS_ACCESS_KEY_ID != \"TU_ACCESS_KEY_AQUI\":\n",
    "    comprehend = boto3.client(\n",
    "        'comprehend',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    print(\"âœ… Credenciales configuradas manualmente\")\n",
    "else:\n",
    "    print(\"âš ï¸ Reemplaza las credenciales si es necesario\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Datos CientÃ­ficos de Muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos cientÃ­ficos\n",
    "SCIENTIFIC_TEXTS = {\n",
    "    \"Reporte SÃ­smico\": \"\"\"\n",
    "    El Instituto GeofÃ­sico del PerÃº reporta actividad sÃ­smica significativa en la regiÃ³n sur. \n",
    "    Los anÃ¡lisis preliminares indican un evento de magnitud 6.2 Mw con epicentro a 45 kilÃ³metros \n",
    "    de profundidad. Las estaciones de monitoreo registraron ondas P y S caracterÃ­sticas de \n",
    "    sismos tectÃ³nicos. Se recomienda mantener protocolos de seguridad en las zonas urbanas cercanas.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Alerta de Emergencia\": \"\"\"\n",
    "    ALERTA SÃSMICA: Se ha detectado un sismo de magnitud 5.8 en la costa peruana. \n",
    "    Tiempo estimado de llegada a Lima: 2 minutos. Busque refugio inmediatamente. \n",
    "    AlÃ©jese de ventanas y objetos que puedan caer. Mantenga la calma y siga los procedimientos.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Abstract CientÃ­fico\": \"\"\"\n",
    "    This study analyzes volcanic activity patterns in the Andes mountain range using \n",
    "    satellite imagery and seismic data. Results show increased thermal anomalies \n",
    "    correlating with micro-seismic events. The findings suggest enhanced monitoring \n",
    "    protocols for early volcanic eruption detection.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"ðŸ“š Textos cientÃ­ficos cargados:\")\n",
    "for i, (title, text) in enumerate(SCIENTIFIC_TEXTS.items(), 1):\n",
    "    word_count = len(text.split())\n",
    "    print(f\"  {i}. {title} ({word_count} palabras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” FunciÃ³n de AnÃ¡lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_with_comprehend(text, text_name):\n",
    "    \"\"\"Analiza texto usando Amazon Comprehend\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ”„ Analizando: {text_name}\")\n",
    "        \n",
    "        # Limpiar texto\n",
    "        clean_text = text.strip().replace('\\n', ' ')\n",
    "        \n",
    "        # Detectar idioma\n",
    "        language_result = comprehend.detect_dominant_language(Text=clean_text)\n",
    "        dominant_language = language_result['Languages'][0]['LanguageCode']\n",
    "        print(f\"  ðŸ“ Idioma: {dominant_language}\")\n",
    "        \n",
    "        results = {\n",
    "            'text_name': text_name,\n",
    "            'language': dominant_language,\n",
    "            'word_count': len(clean_text.split())\n",
    "        }\n",
    "        \n",
    "        # Detectar entidades\n",
    "        entities_result = comprehend.detect_entities(\n",
    "            Text=clean_text,\n",
    "            LanguageCode=dominant_language\n",
    "        )\n",
    "        results['entities'] = entities_result['Entities']\n",
    "        print(f\"  ðŸ·ï¸ Entidades: {len(results['entities'])}\")\n",
    "        \n",
    "        # Frases clave\n",
    "        keyphrases_result = comprehend.detect_key_phrases(\n",
    "            Text=clean_text,\n",
    "            LanguageCode=dominant_language\n",
    "        )\n",
    "        results['key_phrases'] = keyphrases_result['KeyPhrases']\n",
    "        print(f\"  ðŸ”‘ Frases clave: {len(results['key_phrases'])}\")\n",
    "        \n",
    "        # Sentimientos\n",
    "        sentiment_result = comprehend.detect_sentiment(\n",
    "            Text=clean_text,\n",
    "            LanguageCode=dominant_language\n",
    "        )\n",
    "        results['sentiment'] = sentiment_result['Sentiment']\n",
    "        results['sentiment_scores'] = sentiment_result['SentimentScore']\n",
    "        print(f\"  ðŸ˜Š Sentimiento: {results['sentiment']}\")\n",
    "        \n",
    "        results['success'] = True\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return {'success': False, 'error': str(e)}\n",
    "\n",
    "print(\"âœ… FunciÃ³n de anÃ¡lisis creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š FunciÃ³n de VisualizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(analysis_result):\n",
    "    \"\"\"Visualiza resultados del anÃ¡lisis\"\"\"\n",
    "    if not analysis_result.get('success'):\n",
    "        print(f\"âŒ Error: {analysis_result.get('error')}\")\n",
    "        return\n",
    "    \n",
    "    text_name = analysis_result['text_name']\n",
    "    \n",
    "    # Crear grÃ¡ficos\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'AnÃ¡lisis: {text_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Tipos de entidades\n",
    "    if analysis_result['entities']:\n",
    "        entity_types = [e['Type'] for e in analysis_result['entities']]\n",
    "        entity_counts = Counter(entity_types)\n",
    "        \n",
    "        ax1.bar(entity_counts.keys(), entity_counts.values(), color='lightblue')\n",
    "        ax1.set_title('Entidades Detectadas')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'Sin entidades', ha='center', transform=ax1.transAxes)\n",
    "        ax1.set_title('Entidades Detectadas')\n",
    "    \n",
    "    # 2. Frases clave\n",
    "    if analysis_result['key_phrases']:\n",
    "        top_phrases = sorted(analysis_result['key_phrases'], \n",
    "                           key=lambda x: x['Score'], reverse=True)[:6]\n",
    "        phrases = [p['Text'][:25] + '...' if len(p['Text']) > 25 else p['Text'] for p in top_phrases]\n",
    "        scores = [p['Score'] for p in top_phrases]\n",
    "        \n",
    "        ax2.barh(phrases, scores, color='lightgreen')\n",
    "        ax2.set_title('Frases Clave (Top 6)')\n",
    "        ax2.set_xlabel('Relevancia')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Sin frases clave', ha='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Frases Clave')\n",
    "    \n",
    "    # 3. Sentimientos\n",
    "    sentiment_scores = analysis_result['sentiment_scores']\n",
    "    sentiments = ['Positive', 'Negative', 'Neutral', 'Mixed']\n",
    "    scores = [sentiment_scores[s] for s in sentiments]\n",
    "    colors = ['green', 'red', 'gray', 'orange']\n",
    "    \n",
    "    ax3.pie(scores, labels=sentiments, colors=colors, autopct='%1.1f%%')\n",
    "    ax3.set_title(f'Sentimientos\\n(Dominante: {analysis_result[\"sentiment\"]})')\n",
    "    \n",
    "    # 4. EstadÃ­sticas\n",
    "    ax4.axis('off')\n",
    "    stats = f\"\"\"ðŸ“Š EstadÃ­sticas:\n",
    "\n",
    "Palabras: {analysis_result['word_count']}\n",
    "Entidades: {len(analysis_result['entities'])}\n",
    "Frases clave: {len(analysis_result['key_phrases'])}\n",
    "Idioma: {analysis_result['language'].upper()}\"\"\"\n",
    "    ax4.text(0.1, 0.7, stats, fontsize=12, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar entidades\n",
    "    if analysis_result['entities']:\n",
    "        print(f\"\\nðŸ·ï¸ ENTIDADES EN '{text_name.upper()}'\")\n",
    "        print(\"=\" * 50)\n",
    "        for entity in analysis_result['entities'][:8]:\n",
    "            print(f\"â€¢ {entity['Text']} ({entity['Type']}) - {entity['Score']:.2f}\")\n",
    "\n",
    "print(\"âœ… FunciÃ³n de visualizaciÃ³n creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Ejercicio 1: AnÃ¡lisis de Reporte SÃ­smico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar reporte sÃ­smico\n",
    "text_name = \"Reporte SÃ­smico\"\n",
    "text_content = SCIENTIFIC_TEXTS[text_name]\n",
    "\n",
    "print(f\"ðŸ“„ Analizando: {text_name}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Realizar anÃ¡lisis\n",
    "seismic_analysis = analyze_text_with_comprehend(text_content, text_name)\n",
    "\n",
    "# Visualizar\n",
    "if seismic_analysis.get('success'):\n",
    "    visualize_results(seismic_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš¨ Ejercicio 2: AnÃ¡lisis de Alerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar alerta\n",
    "text_name = \"Alerta de Emergencia\"\n",
    "text_content = SCIENTIFIC_TEXTS[text_name]\n",
    "\n",
    "print(f\"ðŸš¨ Analizando: {text_name}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "alert_analysis = analyze_text_with_comprehend(text_content, text_name)\n",
    "\n",
    "if alert_analysis.get('success'):\n",
    "    visualize_results(alert_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ›ï¸ Widget Interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget para anÃ¡lisis interactivo\n",
    "def interactive_analysis(text_selection):\n",
    "    text_content = SCIENTIFIC_TEXTS[text_selection]\n",
    "    print(f\"ðŸ” Analizando: {text_selection}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result = analyze_text_with_comprehend(text_content, text_selection)\n",
    "    if result.get('success'):\n",
    "        visualize_results(result)\n",
    "    return result\n",
    "\n",
    "# Crear widget\n",
    "text_selector = widgets.Dropdown(\n",
    "    options=list(SCIENTIFIC_TEXTS.keys()),\n",
    "    description='Texto:'\n",
    ")\n",
    "\n",
    "interactive_widget = widgets.interactive(interactive_analysis, text_selection=text_selector)\n",
    "display(interactive_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Casos de Uso Reales\n",
    "\n",
    "### Amazon Comprehend en Ciencias:\n",
    "- ðŸ“Š **AnÃ¡lisis de literatura**: Procesar miles de papers automÃ¡ticamente\n",
    "- ðŸš¨ **Sistemas de alerta**: Analizar tono y urgencia de comunicaciones\n",
    "- ðŸ” **ExtracciÃ³n de datos**: Identificar entidades cientÃ­ficas en textos\n",
    "- ðŸ“ˆ **AnÃ¡lisis de tendencias**: Detectar patrones en grandes volÃºmenes de texto\n",
    "- ðŸ“ **ClasificaciÃ³n**: Organizar documentos por tema y sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ValidaciÃ³n del MÃ³dulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_module():\n",
    "    checks = {\n",
    "        \"Credenciales configuradas\": False,\n",
    "        \"AnÃ¡lisis realizado\": False,\n",
    "        \"Widget usado\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        comprehend.detect_dominant_language(Text=\"Test\")\n",
    "        checks[\"Credenciales configuradas\"] = True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if 'seismic_analysis' in globals() and seismic_analysis.get('success'):\n",
    "        checks[\"AnÃ¡lisis realizado\"] = True\n",
    "        checks[\"Widget usado\"] = True\n",
    "    \n",
    "    print(\"ðŸ“‹ VALIDACIÃ“N MÃ“DULO 2 - COMPREHEND\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for check, status in checks.items():\n",
    "        icon = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"{icon} {check}\")\n",
    "    \n",
    "    completed = sum(checks.values())\n",
    "    total = len(checks)\n",
    "    print(f\"\\nðŸ“Š Progreso: {completed}/{total} ({completed/total*100:.0f}%)\")\n",
    "    \n",
    "    if completed >= 2:\n",
    "        print(\"\\nðŸŽ‰ Â¡MÃ“DULO COMPLETADO!\")\n",
    "        print(\"âž¡ï¸ ContinÃºa con MÃ³dulo 3: Textract\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Completa los ejercicios faltantes\")\n",
    "    \n",
    "    return completed >= 2\n",
    "\n",
    "module_completed = validate_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ PrÃ³ximo MÃ³dulo\n",
    "\n",
    "**ðŸ“„ MÃ³dulo 3: OCR con Amazon Textract**\n",
    "\n",
    "---\n",
    "\n",
    "*MÃ³dulo 2 de 6 completado* âœ…"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}