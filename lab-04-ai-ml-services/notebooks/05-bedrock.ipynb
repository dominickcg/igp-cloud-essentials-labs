{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√≥dulo 5: IA Generativa con Amazon Bedrock\n",
    "\n",
    "**Duraci√≥n**: 30 minutos  \n",
    "**Objetivo**: Dominar la IA generativa para crear contenido cient√≠fico y c√≥digo usando Amazon Bedrock\n",
    "\n",
    "## ¬øQu√© aprender√°s?\n",
    "- **Parte A - Generaci√≥n de Texto**: Crear reportes cient√≠ficos, res√∫menes e informes t√©cnicos\n",
    "- **Parte B - Generaci√≥n de C√≥digo**: Desarrollar scripts de an√°lisis de datos y funciones cient√≠ficas\n",
    "- Usar diferentes modelos de IA generativa (Claude, Titan)\n",
    "- Aplicar prompting efectivo para casos cient√≠ficos\n",
    "- Configurar par√°metros avanzados (temperatura, top-p)\n",
    "- Comparar resultados entre modelos\n",
    "\n",
    "## Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "import sys\n",
    "!{sys.executable} -m pip install boto3 ipywidgets matplotlib pandas numpy --quiet\n",
    "\n",
    "print(\"‚úÖ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, Code\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar cliente de Amazon Bedrock\n",
    "try:\n",
    "    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "    print(\"‚úÖ Cliente Bedrock configurado correctamente\")\n",
    "    print(\"‚úÖ Usando credenciales IAM autom√°ticas de SageMaker\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error: Verificar permisos IAM para Bedrock\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Disponibles en Bedrock\n",
    "\n",
    "Configuraremos diferentes modelos para comparar sus capacidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos disponibles en Bedrock\n",
    "MODELOS_BEDROCK = {\n",
    "    \"claude_haiku\": {\n",
    "        \"id\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        \"nombre\": \"Claude 3 Haiku\",\n",
    "        \"fortaleza\": \"R√°pido y eficiente\",\n",
    "        \"uso\": \"Tareas simples, c√≥digo b√°sico\"\n",
    "    },\n",
    "    \"claude_sonnet\": {\n",
    "        \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        \"nombre\": \"Claude 3 Sonnet\",\n",
    "        \"fortaleza\": \"Balance velocidad/calidad\",\n",
    "        \"uso\": \"An√°lisis complejo, reportes\"\n",
    "    },\n",
    "    \"titan_text\": {\n",
    "        \"id\": \"amazon.titan-text-express-v1\",\n",
    "        \"nombre\": \"Amazon Titan Text\",\n",
    "        \"fortaleza\": \"Optimizado para AWS\",\n",
    "        \"uso\": \"Res√∫menes, clasificaci√≥n\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Modelos configurados para el laboratorio:\")\n",
    "for key, modelo in MODELOS_BEDROCK.items():\n",
    "    print(f\"  ‚Ä¢ {modelo['nombre']}: {modelo['fortaleza']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE A: GENERACI√ìN DE CONTENIDO CIENT√çFICO\n",
    "\n",
    "## Casos de Uso para Generaci√≥n de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de uso para generaci√≥n de texto cient√≠fico\n",
    "CASOS_TEXTO = {\n",
    "    \"reporte_sismico\": {\n",
    "        \"prompt\": \"Genera un reporte t√©cnico sobre un sismo de magnitud 6.2 ocurrido en la regi√≥n de Ica, Per√∫. Incluye: ubicaci√≥n exacta, profundidad, intensidad, da√±os preliminares y recomendaciones.\",\n",
    "        \"tipo\": \"reporte_t√©cnico\",\n",
    "        \"longitud\": \"500-700 palabras\"\n",
    "    },\n",
    "    \"resumen_investigacion\": {\n",
    "        \"prompt\": \"Crea un resumen ejecutivo sobre los avances en predicci√≥n s√≠smica usando machine learning. Enf√≥cate en: metodolog√≠as actuales, precisi√≥n alcanzada, limitaciones y futuras direcciones de investigaci√≥n.\",\n",
    "        \"tipo\": \"resumen_ejecutivo\",\n",
    "        \"longitud\": \"300-400 palabras\"\n",
    "    },\n",
    "    \"protocolo_emergencia\": {\n",
    "        \"prompt\": \"Desarrolla un protocolo de emergencia para instituciones cient√≠ficas durante eventos s√≠smicos. Incluye: procedimientos de evacuaci√≥n, protecci√≥n de equipos, comunicaciones y continuidad operativa.\",\n",
    "        \"tipo\": \"protocolo_operativo\",\n",
    "        \"longitud\": \"400-500 palabras\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Casos de uso para generaci√≥n de texto cient√≠fico:\")\n",
    "for nombre, caso in CASOS_TEXTO.items():\n",
    "    print(f\"  ‚Ä¢ {nombre.replace('_', ' ').title()}: {caso['tipo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motor de Generaci√≥n de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_contenido_cientifico(prompt, modelo_key=\"claude_haiku\", temperatura=0.7, max_tokens=1000):\n",
    "    \"\"\"\n",
    "    Genera contenido cient√≠fico usando diferentes modelos de Bedrock\n",
    "    \"\"\"\n",
    "    modelo = MODELOS_BEDROCK[modelo_key]\n",
    "    print(f\"\\nü§ñ Generando con {modelo['nombre']}...\")\n",
    "    \n",
    "    try:\n",
    "        if \"claude\" in modelo_key:\n",
    "            # Formato para modelos Claude\n",
    "            body = json.dumps({\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": temperatura,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "        else:\n",
    "            # Formato para Titan\n",
    "            body = json.dumps({\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": max_tokens,\n",
    "                    \"temperature\": temperatura,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=modelo[\"id\"],\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        \n",
    "        if \"claude\" in modelo_key:\n",
    "            contenido = response_body['content'][0]['text']\n",
    "        else:\n",
    "            contenido = response_body['results'][0]['outputText']\n",
    "        \n",
    "        print(f\"‚úì Contenido generado: {len(contenido)} caracteres\")\n",
    "        \n",
    "        return {\n",
    "            'contenido': contenido,\n",
    "            'modelo': modelo['nombre'],\n",
    "            'parametros': {'temperatura': temperatura, 'max_tokens': max_tokens},\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Motor de generaci√≥n de texto configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio A1: Generar Reporte S√≠smico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte s√≠smico\n",
    "caso_reporte = CASOS_TEXTO['reporte_sismico']\n",
    "reporte_resultado = generar_contenido_cientifico(\n",
    "    caso_reporte['prompt'],\n",
    "    modelo_key=\"claude_sonnet\",\n",
    "    temperatura=0.3,  # M√°s conservador para reportes t√©cnicos\n",
    "    max_tokens=800\n",
    ")\n",
    "\n",
    "if reporte_resultado:\n",
    "    print(\"\\nüìÑ REPORTE S√çSMICO GENERADO:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(Markdown(reporte_resultado['contenido']))\n",
    "    \n",
    "    print(f\"\\nüìä Detalles de generaci√≥n:\")\n",
    "    print(f\"‚Ä¢ Modelo: {reporte_resultado['modelo']}\")\n",
    "    print(f\"‚Ä¢ Temperatura: {reporte_resultado['parametros']['temperatura']}\")\n",
    "    print(f\"‚Ä¢ Caracteres: {len(reporte_resultado['contenido'])}\")\n",
    "else:\n",
    "    print(\"No se pudo generar el reporte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio A2: Generar Resumen de Investigaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen de investigaci√≥n\n",
    "caso_resumen = CASOS_TEXTO['resumen_investigacion']\n",
    "resumen_resultado = generar_contenido_cientifico(\n",
    "    caso_resumen['prompt'],\n",
    "    modelo_key=\"claude_haiku\",\n",
    "    temperatura=0.5,\n",
    "    max_tokens=600\n",
    ")\n",
    "\n",
    "if resumen_resultado:\n",
    "    print(\"\\nüìã RESUMEN DE INVESTIGACI√ìN GENERADO:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(Markdown(resumen_resultado['contenido']))\n",
    "    \n",
    "    print(f\"\\nüìä Detalles de generaci√≥n:\")\n",
    "    print(f\"‚Ä¢ Modelo: {resumen_resultado['modelo']}\")\n",
    "    print(f\"‚Ä¢ Temperatura: {resumen_resultado['parametros']['temperatura']}\")\n",
    "    print(f\"‚Ä¢ Caracteres: {len(resumen_resultado['contenido'])}\")\n",
    "else:\n",
    "    print(\"No se pudo generar el resumen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE B: GENERACI√ìN DE C√ìDIGO\n",
    "\n",
    "## Casos de Uso para Generaci√≥n de C√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de uso para generaci√≥n de c√≥digo cient√≠fico\n",
    "CASOS_CODIGO = {\n",
    "    \"analisis_sismico\": {\n",
    "        \"descripcion\": \"Crear una funci√≥n que analice datos s√≠smicos y calcule la magnitud promedio, desviaci√≥n est√°ndar y identifique eventos an√≥malos (magnitud > 5.0)\",\n",
    "        \"datos_ejemplo\": \"Lista de magnitudes s√≠smicas: [3.2, 4.1, 2.8, 5.5, 3.7, 4.2, 6.1, 3.9, 4.5, 3.1]\",\n",
    "        \"tipo\": \"an√°lisis_estad√≠stico\"\n",
    "    },\n",
    "    \"visualizacion_geologica\": {\n",
    "        \"descripcion\": \"Generar c√≥digo para crear un gr√°fico de dispersi√≥n que muestre la relaci√≥n entre profundidad y magnitud de sismos, con colores seg√∫n la intensidad\",\n",
    "        \"datos_ejemplo\": \"DataFrame con columnas: profundidad, magnitud, intensidad\",\n",
    "        \"tipo\": \"visualizaci√≥n\"\n",
    "    },\n",
    "    \"procesamiento_se√±ales\": {\n",
    "        \"descripcion\": \"Crear una funci√≥n que aplique un filtro pasa-bajas a se√±ales s√≠smicas para eliminar ruido de alta frecuencia usando scipy\",\n",
    "        \"datos_ejemplo\": \"Array numpy con datos de aceleraci√≥n en el tiempo\",\n",
    "        \"tipo\": \"procesamiento_se√±ales\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Casos de uso para generaci√≥n de c√≥digo cient√≠fico:\")\n",
    "for nombre, info in CASOS_CODIGO.items():\n",
    "    print(f\"  ‚Ä¢ {nombre.replace('_', ' ').title()}: {info['tipo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motor de Generaci√≥n de C√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_codigo_cientifico(descripcion_tarea, tipo_codigo, datos_ejemplo=\"\"):\n",
    "    \"\"\"\n",
    "    Genera c√≥digo Python para tareas cient√≠ficas usando IA\n",
    "    \"\"\"\n",
    "    print(f\"\\nü§ñ Generando c√≥digo para: {descripcion_tarea[:50]}...\")\n",
    "    print(f\"Tipo: {tipo_codigo}\")\n",
    "    \n",
    "    # Crear prompt especializado para c√≥digo cient√≠fico\n",
    "    prompt = f\"\"\"Eres un experto en programaci√≥n cient√≠fica con Python. \n",
    "    \n",
    "Tarea: {descripcion_tarea}\n",
    "Tipo de c√≥digo: {tipo_codigo}\n",
    "Datos de ejemplo: {datos_ejemplo}\n",
    "\n",
    "Genera c√≥digo Python que:\n",
    "1. Sea funcional y ejecutable\n",
    "2. Incluya comentarios explicativos\n",
    "3. Use librer√≠as cient√≠ficas apropiadas (numpy, pandas, matplotlib, scipy)\n",
    "4. Maneje errores b√°sicos\n",
    "5. Incluya un ejemplo de uso con los datos proporcionados\n",
    "\n",
    "Responde SOLO con el c√≥digo Python, sin explicaciones adicionales:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Usar Claude 3 Haiku para generaci√≥n de c√≥digo\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.2,  # M√°s determin√≠stico para c√≥digo\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        codigo_generado = response_body['content'][0]['text']\n",
    "        \n",
    "        print(f\"‚úì C√≥digo generado exitosamente\")\n",
    "        print(f\"‚úì L√≠neas de c√≥digo: {len(codigo_generado.split())}\")\n",
    "        \n",
    "        return {\n",
    "            'codigo': codigo_generado,\n",
    "            'descripcion': descripcion_tarea,\n",
    "            'tipo': tipo_codigo,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error en generaci√≥n: {e}\")\n",
    "        return None\n",
    "\n",
    "def ejecutar_codigo_generado(codigo_resultado):\n",
    "    \"\"\"\n",
    "    Ejecuta el c√≥digo generado de manera segura\n",
    "    \"\"\"\n",
    "    if not codigo_resultado:\n",
    "        print(\"‚ùå No hay c√≥digo para ejecutar\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nüöÄ Ejecutando c√≥digo generado...\")\n",
    "    \n",
    "    try:\n",
    "        # Ejecutar el c√≥digo en el contexto actual\n",
    "        exec(codigo_resultado['codigo'], globals())\n",
    "        print(f\"‚úÖ C√≥digo ejecutado exitosamente\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en ejecuci√≥n: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"‚úÖ Motor de generaci√≥n de c√≥digo configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio B1: Generar An√°lisis Estad√≠stico de Datos S√≠smicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar c√≥digo para an√°lisis s√≠smico\n",
    "caso_sismico = CASOS_CODIGO['analisis_sismico']\n",
    "codigo_sismico = generar_codigo_cientifico(\n",
    "    caso_sismico['descripcion'],\n",
    "    caso_sismico['tipo'],\n",
    "    caso_sismico['datos_ejemplo']\n",
    ")\n",
    "\n",
    "if codigo_sismico:\n",
    "    print(\"\\nüìù C√ìDIGO GENERADO:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(Code(codigo_sismico['codigo'], language='python'))\n",
    "    \n",
    "    # Ejecutar el c√≥digo generado\n",
    "    ejecutar_codigo_generado(codigo_sismico)\n",
    "else:\n",
    "    print(\"No se pudo generar el c√≥digo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio B2: Generar Visualizaci√≥n Geol√≥gica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar c√≥digo para visualizaci√≥n\n",
    "caso_viz = CASOS_CODIGO['visualizacion_geologica']\n",
    "codigo_viz = generar_codigo_cientifico(\n",
    "    caso_viz['descripcion'],\n",
    "    caso_viz['tipo'],\n",
    "    caso_viz['datos_ejemplo']\n",
    ")\n",
    "\n",
    "if codigo_viz:\n",
    "    print(\"\\nüìä C√ìDIGO DE VISUALIZACI√ìN GENERADO:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(Code(codigo_viz['codigo'], language='python'))\n",
    "    \n",
    "    # Ejecutar el c√≥digo generado\n",
    "    ejecutar_codigo_generado(codigo_viz)\n",
    "else:\n",
    "    print(\"No se pudo generar el c√≥digo de visualizaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar diferentes modelos para la misma tarea\n",
    "prompt_comparacion = \"Explica en 100 palabras qu√© es la sismolog√≠a y su importancia para la sociedad.\"\n",
    "\n",
    "print(\"üîÑ COMPARANDO MODELOS DE BEDROCK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "modelos_comparar = ['claude_haiku', 'claude_sonnet']\n",
    "resultados_comparacion = {}\n",
    "\n",
    "for modelo_key in modelos_comparar:\n",
    "    print(f\"\\nü§ñ Generando con {MODELOS_BEDROCK[modelo_key]['nombre']}...\")\n",
    "    resultado = generar_contenido_cientifico(\n",
    "        prompt_comparacion,\n",
    "        modelo_key=modelo_key,\n",
    "        temperatura=0.5,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    if resultado:\n",
    "        resultados_comparacion[modelo_key] = resultado\n",
    "        print(f\"\\n**{resultado['modelo']}:**\")\n",
    "        display(Markdown(resultado['contenido']))\n",
    "        print(f\"Caracteres: {len(resultado['contenido'])}\")\n",
    "\n",
    "print(\"\\n‚úÖ Comparaci√≥n completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del Laboratorio Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen completo del laboratorio\n",
    "print(\"üìà RESUMEN COMPLETO - AMAZON BEDROCK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parte A - Contenido generado\n",
    "contenidos_generados = []\n",
    "if 'reporte_resultado' in globals() and reporte_resultado:\n",
    "    contenidos_generados.append(('Reporte S√≠smico', reporte_resultado))\n",
    "if 'resumen_resultado' in globals() and resumen_resultado:\n",
    "    contenidos_generados.append(('Resumen Investigaci√≥n', resumen_resultado))\n",
    "\n",
    "print(f\"\\nüìÑ PARTE A - GENERACI√ìN DE TEXTO:\")\n",
    "total_caracteres_texto = 0\n",
    "for nombre, resultado in contenidos_generados:\n",
    "    caracteres = len(resultado['contenido'])\n",
    "    total_caracteres_texto += caracteres\n",
    "    print(f\"‚Ä¢ {nombre}: {caracteres} caracteres ({resultado['modelo']})\")\n",
    "\n",
    "# Parte B - C√≥digo generado\n",
    "codigos_generados = []\n",
    "if 'codigo_sismico' in globals() and codigo_sismico:\n",
    "    codigos_generados.append(('An√°lisis S√≠smico', codigo_sismico))\n",
    "if 'codigo_viz' in globals() and codigo_viz:\n",
    "    codigos_generados.append(('Visualizaci√≥n Geol√≥gica', codigo_viz))\n",
    "\n",
    "print(f\"\\nüíª PARTE B - GENERACI√ìN DE C√ìDIGO:\")\n",
    "total_lineas_codigo = 0\n",
    "for nombre, codigo in codigos_generados:\n",
    "    lineas = len(codigo['codigo'].split('\\n'))\n",
    "    total_lineas_codigo += lineas\n",
    "    print(f\"‚Ä¢ {nombre}: {lineas} l√≠neas de c√≥digo ({codigo['tipo']})\")\n",
    "\n",
    "print(f\"\\nüéØ TOTALES:\")\n",
    "print(f\"‚Ä¢ Contenido cient√≠fico generado: {len(contenidos_generados)} documentos\")\n",
    "print(f\"‚Ä¢ C√≥digo cient√≠fico generado: {len(codigos_generados)} scripts\")\n",
    "print(f\"‚Ä¢ Total caracteres de texto: {total_caracteres_texto}\")\n",
    "print(f\"‚Ä¢ Total l√≠neas de c√≥digo: {total_lineas_codigo}\")\n",
    "print(f\"‚Ä¢ Modelos utilizados: Claude 3 Haiku, Claude 3 Sonnet\")\n",
    "\n",
    "print(f\"\\nüîß CAPACIDADES DEMOSTRADAS:\")\n",
    "capacidades = [\n",
    "    'Generaci√≥n de reportes t√©cnicos',\n",
    "    'Creaci√≥n de res√∫menes ejecutivos',\n",
    "    'Desarrollo de c√≥digo de an√°lisis estad√≠stico',\n",
    "    'Generaci√≥n de scripts de visualizaci√≥n',\n",
    "    'Comparaci√≥n entre modelos de IA',\n",
    "    'Configuraci√≥n de par√°metros avanzados'\n",
    "]\n",
    "\n",
    "for capacidad in capacidades:\n",
    "    print(f\"‚Ä¢ {capacidad}\")\n",
    "\n",
    "print(\"\\n‚úì Laboratorio Amazon Bedrock completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos de Uso en Investigaci√≥n Cient√≠fica\n",
    "\n",
    "### Amazon Bedrock para Ciencias:\n",
    "- **Generaci√≥n de reportes**: Crear informes t√©cnicos y documentaci√≥n cient√≠fica\n",
    "- **Res√∫menes de literatura**: Sintetizar papers y estudios de investigaci√≥n\n",
    "- **Traducci√≥n t√©cnica**: Adaptar contenido cient√≠fico entre idiomas\n",
    "- **Generaci√≥n de c√≥digo**: Crear scripts de an√°lisis y procesamiento de datos\n",
    "- **Documentaci√≥n autom√°tica**: Generar comentarios y documentaci√≥n de c√≥digo\n",
    "- **An√°lisis de datos**: Desarrollar algoritmos de procesamiento cient√≠fico\n",
    "- **Protocolos operativos**: Crear procedimientos y gu√≠as t√©cnicas\n",
    "- **Comunicaci√≥n cient√≠fica**: Adaptar contenido t√©cnico para diferentes audiencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaci√≥n del M√≥dulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_modulo_bedrock():\n",
    "    verificaciones = {\n",
    "        \"Bedrock configurado\": 'bedrock' in globals(),\n",
    "        \"Contenido cient√≠fico generado\": False,\n",
    "        \"C√≥digo cient√≠fico generado\": False,\n",
    "        \"Comparaci√≥n de modelos realizada\": False\n",
    "    }\n",
    "    \n",
    "    # Verificar generaci√≥n de contenido\n",
    "    if 'reporte_resultado' in globals() and reporte_resultado:\n",
    "        verificaciones[\"Contenido cient√≠fico generado\"] = len(reporte_resultado.get('contenido', '')) > 0\n",
    "    \n",
    "    # Verificar generaci√≥n de c√≥digo\n",
    "    if 'codigo_sismico' in globals() and codigo_sismico:\n",
    "        verificaciones[\"C√≥digo cient√≠fico generado\"] = len(codigo_sismico.get('codigo', '')) > 0\n",
    "    \n",
    "    # Verificar comparaci√≥n de modelos\n",
    "    if 'resultados_comparacion' in globals() and resultados_comparacion:\n",
    "        verificaciones[\"Comparaci√≥n de modelos realizada\"] = len(resultados_comparacion) > 1\n",
    "    \n",
    "    print(\"VALIDACI√ìN M√ìDULO 5 - AMAZON BEDROCK\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    for verificacion, estado in verificaciones.items():\n",
    "        icono = \"‚úì\" if estado else \"‚úó\"\n",
    "        print(f\"{icono} {verificacion}\")\n",
    "    \n",
    "    completadas = sum(verificaciones.values())\n",
    "    total = len(verificaciones)\n",
    "    porcentaje = (completadas/total)*100\n",
    "    \n",
    "    print(f\"\\nProgreso: {completadas}/{total} ({porcentaje:.0f}%)\")\n",
    "    \n",
    "    if completadas >= 3:\n",
    "        print(\"\\nüéâ ¬°M√ìDULO BEDROCK COMPLETADO!\")\n",
    "        print(\"Has dominado la IA generativa para contenido y c√≥digo cient√≠fico\")\n",
    "        print(\"üèÅ ¬°LABORATORIO COMPLETO! Has explorado todos los servicios de AWS AI/ML\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Completa m√°s ejercicios de IA generativa\")\n",
    "    \n",
    "    return completadas >= 3\n",
    "\n",
    "modulo_completado = validar_modulo_bedrock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ¬°Laboratorio Completado!\n",
    "\n",
    "**Has explorado 5 servicios de AWS AI/ML:**\n",
    "1. **Amazon Rekognition** - An√°lisis de im√°genes satelitales\n",
    "2. **Amazon Comprehend** - Procesamiento de texto cient√≠fico\n",
    "3. **Amazon Textract** - OCR inteligente de documentos\n",
    "4. **Amazon Polly** - S√≠ntesis de voz para alertas\n",
    "5. **Amazon Bedrock** - IA generativa para contenido y c√≥digo cient√≠fico\n",
    "\n",
    "### üéØ Logros Alcanzados:\n",
    "- Procesamiento de im√°genes geol√≥gicas\n",
    "- An√°lisis de documentos cient√≠ficos\n",
    "- Digitalizaci√≥n de formularios y tablas\n",
    "- Creaci√≥n de alertas de audio\n",
    "- Generaci√≥n de reportes t√©cnicos\n",
    "- Desarrollo de c√≥digo cient√≠fico con IA\n",
    "\n",
    "---\n",
    "\n",
    "*M√≥dulo 5 de 5 completado*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
